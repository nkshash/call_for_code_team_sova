# -*- coding: utf-8 -*-
"""Unet_image_enchancement.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1upcUCmkDF84cElSvinXPzAaY0fLuo27c
"""

import zipfile
import os

def unzip_folder(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    print('extraction complete')

zip_file_path = './noise.zip'
extract_to_directory = './'

unzip_folder(zip_file_path, extract_to_directory)

import cv2
import os
import numpy as np

def resize_images(input_folder, output_folder, target_size=(300, 300)):
    os.makedirs(output_folder, exist_ok=True)

    for filename in os.listdir(input_folder):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            image_path = os.path.join(input_folder, filename)
            img = cv2.imread(image_path)

            resized_img = cv2.resize(img, target_size)

            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, resized_img)
            print(f"Resized {filename} to {target_size}")


def add_noise_and_blur(input_folder, output_folder, noise_strength=50, blur_kernel_size=(5, 5)):
    os.makedirs(output_folder, exist_ok=True)

    for filename in os.listdir(input_folder):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            image_path = os.path.join(input_folder, filename)
            img = cv2.imread(image_path)

            noise = np.random.normal(0, noise_strength, img.shape).astype(np.uint8)
            noisy_img = cv2.add(img, noise)

            blurred_img = cv2.GaussianBlur(noisy_img, blur_kernel_size, 0)

            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, blurred_img)
            print(f"Processed {filename}")


input_folder = './noise'
output_folder = './add'
noise_strength = 1
blur_kernel_size = (5, 5)
target_size = (224, 224)

resize_images(input_folder, output_folder, target_size)
add_noise_and_blur(output_folder, output_folder, noise_strength, blur_kernel_size)

import tensorflow as tf
import numpy as np
from tensorflow.keras import layers, models
import os

def unet(input_shape):
    inputs = layers.Input(input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)
    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)

    # Decoder
    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)
    up6 = layers.concatenate([up6, conv4], axis=3)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(up6)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)

    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)
    up7 = layers.concatenate([up7, conv3], axis=3)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(up7)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)

    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)
    up8 = layers.concatenate([up8, conv2], axis=3)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(up8)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)

    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)
    up9 = layers.concatenate([up9, conv1], axis=3)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(up9)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)

    outputs = layers.Conv2D(3, 1, activation='sigmoid')(conv9)

    model = models.Model(inputs=inputs, outputs=outputs)
    return model

def load_images(folder_path, target_size=(224, 224)):
    images = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            image_path = os.path.join(folder_path, filename)
            img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)
            img_array = tf.keras.preprocessing.image.img_to_array(img)
            images.append(img_array)
    return np.array(images)

noisy_images_folder = './add'
noisy_images = load_images(noisy_images_folder)


clean_images_folder = './noise'
clean_images = load_images(clean_images_folder)

noisy_images = noisy_images / 255.0
clean_images = clean_images / 255.0

input_shape = (224, 224, 3)
model = unet(input_shape)
model.summary()

model.compile(optimizer='adam', loss='mse')

model.fit(noisy_images, clean_images, batch_size=32, epochs=30, validation_split=0.2)
model.save('unet_model.h5')
model.save('unet.keras')

#accuracy
import tensorflow as tf
import tensorflow.image as tf_image

loaded_model = tf.keras.models.load_model('unet_model.h5')

predicted_images = loaded_model.predict(noisy_images)

psnr = tf_image.psnr(clean_images, predicted_images, max_val=1.0)

ssim = tf_image.ssim(clean_images, predicted_images, max_val=1.0)

avg_psnr = tf.reduce_mean(psnr)
avg_ssim = tf.reduce_mean(ssim)

print("Average PSNR:", avg_psnr.numpy())
print("Average SSIM:", avg_ssim.numpy())


###########run till here only

#don't run this part of the code , this is for test purpose only
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

from tensorflow.keras.models import load_model
model_path = './unet_model.h5'
loaded_model = load_model(model_path)

image_path = './download.png'
image = cv2.imread(image_path)

target_size = (224, 224)
resized_image = cv2.resize(image, target_size)

preprocessed_image = resized_image / 255.0
input_image = np.expand_dims(preprocessed_image, axis=0)

def add_noise(image, noise_strength):
    noise = np.random.normal(0, noise_strength, image.shape).astype(np.uint8)
    noisy_image = cv2.add(image, noise)
    return noisy_image

def apply_gaussian_blur(image, kernel_size):
    blurred_image = cv2.GaussianBlur(image, kernel_size, 0)
    return blurred_image

noise_strength = 1
blur_kernel_size = (5, 5)
noisy_image = add_noise(resized_image, noise_strength)
blurred_image = apply_gaussian_blur(noisy_image, blur_kernel_size)

normalized_blurred_image = blurred_image / 255.0

predicted_image = loaded_model.predict(np.expand_dims(normalized_blurred_image, axis=0))

predicted_image_denormalized = predicted_image[0] * 255.0

cv2_imshow(resized_image)
cv2_imshow(noisy_image)
cv2_imshow(blurred_image)
cv2_imshow(predicted_image_denormalized.astype(np.uint8))